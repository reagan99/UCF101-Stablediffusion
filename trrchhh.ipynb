{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "model = tf.keras.models.load_model('ucf101_subset_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\"\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_2 (Rescaling)     (None, None, None, None   0         \n",
      "                             , 3)                                \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, None, None, None   4049571   \n",
      " ributed)                    , 1280)                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, None, None   129381    \n",
      "                             , 101)                              \n",
      "                                                                 \n",
      " global_average_pooling3d (  (None, 101)               0         \n",
      " GlobalAveragePooling3D)                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4178952 (15.94 MB)\n",
      "Trainable params: 129381 (505.39 KB)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    'ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam',\n",
    "    'BandMarching', 'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress',\n",
    "    'Biking', 'Billiards', 'BlowDryHair', 'BlowingCandles', 'BodyWeightSquats',\n",
    "    'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'BreastStroke', 'BrushingTeeth',\n",
    "    'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen',\n",
    "    'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics',\n",
    "    'FrisbeeCatch', 'FrontCrawl', 'GolfSwing', 'Haircut', 'Hammering', 'HammerThrow',\n",
    "    'HandstandPushups', 'HandstandWalking', 'HeadMassage', 'HighJump', 'HorseRace',\n",
    "    'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow', 'JugglingBalls',\n",
    "    'JumpingJack', 'JumpRope', 'Kayaking', 'Knitting', 'LongJump', 'Lunges',\n",
    "    'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars',\n",
    "    'PizzaTossing', 'PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute',\n",
    "    'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin',\n",
    "    'PoleVault', 'PommelHorse', 'PullUps', 'Punch', 'PushUps', 'Rafting',\n",
    "    'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard',\n",
    "    'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling',\n",
    "    'SoccerPenalty', 'StillRings', 'SumoWrestling', 'Surfing', 'Swing',\n",
    "    'TableTennisShot', 'TaiChi', 'TennisSwing', 'ThrowDiscus', 'TrampolineJumping',\n",
    "    'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog', 'WallPushups',\n",
    "    'WritingOnBoard', 'YoYo'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted class index: [25]\n",
      "Predicted class name: Diving\n",
      "Probabilities: [[1.07147102e-09 3.16574962e-08 6.05890662e-08 1.90081177e-08\n",
      "  1.61140449e-07 1.94340686e-08 5.61583180e-09 9.39981765e-05\n",
      "  1.95116681e-05 1.20651031e-10 2.15166177e-10 2.07148886e-07\n",
      "  1.61664762e-08 3.30183797e-12 4.33979935e-10 2.05558095e-08\n",
      "  2.64128053e-09 7.93943489e-09 4.12558642e-04 6.71420752e-10\n",
      "  2.17018624e-06 4.18109741e-10 1.70084373e-08 7.55724869e-08\n",
      "  1.13782699e-08 9.83509839e-01 4.43505499e-09 1.41818447e-07\n",
      "  4.41385710e-05 1.19006891e-05 4.13499443e-11 5.79241532e-06\n",
      "  5.20200372e-09 8.63448896e-11 1.31288471e-06 2.30408539e-10\n",
      "  1.63925307e-07 2.90622506e-06 1.24399949e-10 1.17815379e-02\n",
      "  5.42821121e-10 1.16883356e-08 6.46549665e-07 4.54059347e-07\n",
      "  5.69759422e-08 2.57200270e-07 2.19018398e-06 2.28821267e-11\n",
      "  6.74517082e-07 3.37286991e-07 2.63162178e-06 4.77600452e-07\n",
      "  1.81504767e-08 5.59187896e-09 1.78056536e-09 1.11900633e-07\n",
      "  3.70450248e-03 1.45178749e-08 2.28846933e-08 4.35448015e-08\n",
      "  1.11328129e-08 1.64949616e-11 1.24904114e-08 3.23688084e-07\n",
      "  1.67032066e-09 1.09362254e-07 1.13581917e-08 6.29085480e-05\n",
      "  4.28942622e-05 2.91972725e-07 2.89253080e-07 3.57207797e-09\n",
      "  8.33357916e-08 1.39447778e-08 2.20960601e-07 2.42457872e-06\n",
      "  3.62848751e-10 1.68635772e-10 5.53985556e-05 5.55982690e-12\n",
      "  4.31544765e-11 3.94967356e-06 5.58168844e-10 1.10753895e-07\n",
      "  1.24335209e-10 3.28815186e-05 9.28326481e-05 2.53251073e-06\n",
      "  1.96306041e-06 5.80459491e-05 2.00732675e-09 2.43713636e-08\n",
      "  9.58281721e-09 1.69297732e-06 1.17948862e-09 4.09174281e-05\n",
      "  9.76123033e-07 9.27739574e-09 6.24139499e-12 2.39542663e-10\n",
      "  1.04850324e-08]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = tf.keras.models.load_model('ucf101_subset_model.h5')\n",
    "\n",
    "def load_video(file_path, num_frames=10, resize_shape=(224, 224)):\n",
    "    cap = cv2.VideoCapture(file_path)\n",
    "    frames = []\n",
    "\n",
    "    while len(frames) < num_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.resize(frame, resize_shape)\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    \n",
    "    frames = np.array(frames)\n",
    "    frames = np.expand_dims(frames, axis=0)  # 추가 배치 차원\n",
    "    frames = frames / 255.0  # 정규화\n",
    "\n",
    "    return frames\n",
    "\n",
    "video_path = 'div.avi'\n",
    "video_frames = load_video(video_path)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = model.predict(video_frames)\n",
    "probabilities = tf.nn.softmax(predictions, axis=-1)\n",
    "predicted_class = np.argmax(probabilities, axis=-1)\n",
    "\n",
    "# 예측 결과 출력\n",
    "print(f'Predicted class index: {predicted_class}')\n",
    "print(f'Predicted class name: {class_names[predicted_class[0]]}')\n",
    "print(f'Probabilities: {probabilities.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt for Generating the Picture:\n",
      "\n",
      "Title: \"Ocean Grace\"\n",
      "\n",
      "Character Description:\n",
      "- The main subject of the drawing is a graceful and skilled female diver in mid-dive, captured in a moment of elegance and precision.\n",
      "- The diver should be portrayed wearing a sleek, form-fitting diving suit that shimmers in the sunlight.\n",
      "- Her face is focused and serene, displaying a sense of determination and passion for her craft.\n",
      "- She has long, flowing hair trailing behind her, adding a sense of movement to the scene.\n",
      "- The diver's body is in a perfect arched position, showcasing her expertise and control in the water.\n",
      "\n",
      "Composition:\n",
      "- The diver is positioned in the center of the composition, occupying the foreground of the image.\n",
      "- The surrounding water is depicted in shades of turquoise and deep blue, with sunlight filtering through the surface, creating dappled patterns on the seabed below.\n",
      "- Include air bubbles rising from the diver's mouth and small, colorful fish darting around her, adding to the dynamic energy of the scene.\n",
      "- Incorporate subtle ripples on the water's surface to enhance the sense of motion and depth.\n",
      "\n",
      "Background:\n",
      "- In the background, depict a stunning underwater seascape with coral reefs, sea plants, and schools of fish to create a vibrant and colorful setting.\n",
      "- Rays of sunlight penetrate the water, casting ethereal beams of light that dance across the ocean floor.\n",
      "- Include distant silhouettes of other divers exploring the underwater world, adding a sense of camaraderie and shared experience.\n",
      "\n",
      "Overall, the composition should convey a sense of harmony, beauty, and skill, capturing the essence of the predicted class name \"Diving\" through the elegant portrayal of the diver and the mesmerizing underwater environment she inhabits.\n"
     ]
    }
   ],
   "source": [
    "# OpenAI 클라이언트 설정\n",
    "client = OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "# 질문 작성하기\n",
    "query = f\"\"\"I will draw a picture of the predicted class name: {class_names[predicted_class[0]]}. Set up the character, composition, \n",
    "and background. And write a prompt for generating the picture. \n",
    "The more detailed, the better. Include all the necessary information for drawing. Make sure the predicted class name is well reflected.\"\"\"\n",
    "\n",
    "# 메시지 설정하기\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that helps provide prompt about drawing a picture.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": query\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# 응답 받기\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:03<00:00,  2.10it/s]\n",
      "100%|██████████| 50/50 [00:04<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved at c:\\ucfdiffu\\generated_image.png\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "def generate_image(prompt, num_inference_steps=50, guidance_scale=7.5, size=(1024, 576)):\n",
    "    image = pipe(prompt, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale).images[0]\n",
    "    image = image.resize(size)\n",
    "    return image\n",
    "\n",
    "answer = class_names[predicted_class[0]]\n",
    "\n",
    "# 이미지 생성\n",
    "prompt = f\"A scene of {answer}\"\n",
    "generated_image = generate_image(prompt)\n",
    "\n",
    "# 이미지 저장\n",
    "current_dir = os.getcwd()\n",
    "output_image_path = os.path.join(current_dir, 'generated_image.png')\n",
    "generated_image.save(output_image_path)\n",
    "print(f'Image saved at {output_image_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffusers import StableVideoDiffusionPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-video-diffusion-img2vid\", torch_dtype=torch.float16, variant=\"fp16\"\n",
    ")\n",
    "\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "# Load the conditioning image\n",
    "image = \"generated_image.png\"\n",
    "image = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "generator = torch.manual_seed(42)\n",
    "\n",
    "frames = pipe(image, decode_chunk_size=2, generator=generator, num_frames=10).frames[0]\n",
    "\n",
    "\n",
    "export_to_video(frames, \"generated.mp4\", fps=7)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
